{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826ae0cb",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "This section imports all necessary Python libraries for image processing, model building, feature extraction (EfficientNet, Zernike), and training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "import mahotas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0975e09",
   "metadata": {},
   "source": [
    "### Define Feature Extractors\n",
    "This part loads EfficientNetB0 (without top layers) to extract features from RGB hand images and defines Zernike moment extraction using Mahotas from binary hand shape diagrams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb6efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "eff_model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "FEATURE_SIZE = base_model.output_shape[-1]  \n",
    "\n",
    "ZERN_ORDER = 8\n",
    "ZERN_RADIUS = 200  \n",
    "ZERN_FEATURE_SIZE = len(mahotas.features.zernike_moments(np.ones((400, 400), dtype=bool), radius=ZERN_RADIUS, degree=ZERN_ORDER))\n",
    "\n",
    "def extract_eff_features(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB').resize((224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        features = eff_model.predict(x, verbose=0)\n",
    "        return features.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        return np.zeros(FEATURE_SIZE)\n",
    "\n",
    "def extract_zernike_features(img_path):\n",
    "    try:\n",
    "        img = imread(img_path)\n",
    "        img_gray = rgb2gray(img)\n",
    "\n",
    "        if img_gray.shape != (400, 400):\n",
    "            print(f\"Warning: {img_path} is not 400x400, found {img_gray.shape}\")\n",
    "\n",
    "        \n",
    "        binarized = img_gray > img_gray.mean()\n",
    "\n",
    "        features = mahotas.features.zernike_moments(binarized, radius=ZERN_RADIUS, degree=ZERN_ORDER)\n",
    "        return np.array(features[:ZERN_FEATURE_SIZE])\n",
    "    except Exception as e:\n",
    "        print(f\"Zernike error processing {img_path}: {e}\")\n",
    "        return np.zeros(ZERN_FEATURE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4475706",
   "metadata": {},
   "source": [
    "### Feature Extraction Functions\n",
    "Defines two functions: one for extracting EfficientNet features and another for computing Zernike moments from grayscale, binarized shape images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame_combined(frame_dir):\n",
    "\n",
    "    left_eff = np.zeros(FEATURE_SIZE)\n",
    "    right_eff = np.zeros(FEATURE_SIZE)\n",
    "\n",
    "\n",
    "    left_zern = [np.zeros(ZERN_FEATURE_SIZE)] * 6\n",
    "    right_zern = [np.zeros(ZERN_FEATURE_SIZE)] * 6\n",
    "\n",
    "\n",
    "    left_hand_dir = os.path.join(frame_dir, 'left_hand')\n",
    "    if os.path.exists(left_hand_dir):\n",
    "\n",
    "        left_img = next((f for f in os.listdir(left_hand_dir) if f.endswith('.png') and not f.startswith('point')), None)\n",
    "        if left_img:\n",
    "            left_eff = extract_eff_features(os.path.join(left_hand_dir, left_img))\n",
    "\n",
    "\n",
    "        results_dir = os.path.join(left_hand_dir, 'results')\n",
    "        if os.path.exists(results_dir):\n",
    "            diagram_files = sorted([f for f in os.listdir(results_dir) if f.startswith('results-') and f.endswith('.png')])[:6]\n",
    "            left_zern = [extract_zernike_features(os.path.join(results_dir, f)) for f in diagram_files]\n",
    "            # Padding if fewer than 6\n",
    "            left_zern += [np.zeros(ZERN_FEATURE_SIZE)] * (6 - len(left_zern))\n",
    "\n",
    " \n",
    "    right_hand_dir = os.path.join(frame_dir, 'right_hand')\n",
    "    if os.path.exists(right_hand_dir):\n",
    "\n",
    "        right_img = next((f for f in os.listdir(right_hand_dir) if f.endswith('.png') and not f.startswith('point')), None)\n",
    "        if right_img:\n",
    "            right_eff = extract_eff_features(os.path.join(right_hand_dir, right_img))\n",
    "\n",
    "        results_dir = os.path.join(right_hand_dir, 'results')\n",
    "        if os.path.exists(results_dir):\n",
    "            diagram_files = sorted([f for f in os.listdir(results_dir) if f.startswith('results-') and f.endswith('.png')])[:6]\n",
    "            right_zern = [extract_zernike_features(os.path.join(results_dir, f)) for f in diagram_files]\n",
    "            # Padding if fewer than 6\n",
    "            right_zern += [np.zeros(ZERN_FEATURE_SIZE)] * (6 - len(right_zern))\n",
    "\n",
    "    combined_eff = np.concatenate([left_eff, right_eff], axis=0)\n",
    "    combined_zern = np.array(left_zern + right_zern)\n",
    "\n",
    "    return combined_eff, combined_zern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2808df",
   "metadata": {},
   "source": [
    "### Build Sequences from Dataset\n",
    "Traverses video directories to extract frame-wise feature sequences for each sign class, returning lists of EfficientNet features, Zernike sequences, and their corresponding labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e08190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences_combined(data_path, label_map=None, limit_labels=39):\n",
    "    # Output lists\n",
    "    eff_seqs, zern_seqs, labels = [], [], []\n",
    "\n",
    "    new_label_map = label_map is None\n",
    "    label_map = label_map or {}\n",
    "    label_counter = max(label_map.values(), default=-1) + 1\n",
    "\n",
    "    for label in sorted(os.listdir(data_path))[:limit_labels]:\n",
    "        label_dir = os.path.join(data_path, label)\n",
    "        if not os.path.isdir(label_dir): continue\n",
    "\n",
    "        if label not in label_map:\n",
    "            label_map[label] = label_counter\n",
    "            label_counter += 1\n",
    "\n",
    "        for video in sorted(os.listdir(label_dir)):\n",
    "            video_dir = os.path.join(label_dir, video)\n",
    "            if not os.path.isdir(video_dir): continue\n",
    "\n",
    "            print(f\"Processing label: {label} | video: {video}\")\n",
    "\n",
    "            eff_seq, zern_seq = [], []\n",
    "\n",
    "            for frame in sorted(os.listdir(video_dir)):\n",
    "                frame_dir = os.path.join(video_dir, frame)\n",
    "                if os.path.isdir(frame_dir):\n",
    "                    eff, zern = process_frame_combined(frame_dir)\n",
    "                    eff_seq.append(eff)\n",
    "                    zern_seq.append(zern)\n",
    "\n",
    "            if eff_seq:\n",
    "                eff_seqs.append(eff_seq)\n",
    "                zern_seqs.append(zern_seq)\n",
    "                labels.append(label_map[label])\n",
    "\n",
    "    outputs = (eff_seqs, zern_seqs, labels)\n",
    "    return (*outputs, label_map) if new_label_map else outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68dd5a7",
   "metadata": {},
   "source": [
    "### Load or Cache Training Data\n",
    "Attempts to load preprocessed training data from disk. If not found, it builds them using the previous function and caches the result as a `.pkl` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af354c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'F:/letters/train'\n",
    "train_cache = 'train_data_dual_stream_letters_10_zern8.pkl'\n",
    "\n",
    "if os.path.exists(train_cache):\n",
    "    with open(train_cache, 'rb') as f:\n",
    "        train_eff, train_zern, train_labels, label_map = pickle.load(f)\n",
    "    print(\"✓ Loaded cached combined training data.\")\n",
    "else:\n",
    "    train_eff, train_zern, train_labels, label_map = build_sequences_combined(train_path)\n",
    "    with open(train_cache, 'wb') as f:\n",
    "        pickle.dump((train_eff, train_zern, train_labels, label_map), f)\n",
    "    print(\"✓ Combined training data preprocessed and cached.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa0a74",
   "metadata": {},
   "source": [
    "### Load or Cache Test Data\n",
    "Same as above, but for test data. Ensures testing features and labels are ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2235f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'F:/letters/test'\n",
    "test_cache = 'test_data_dual_stream_letters_10_zern8.pkl'\n",
    "\n",
    "if os.path.exists(test_cache):\n",
    "    with open(test_cache, 'rb') as f:\n",
    "        test_eff, test_zern, test_labels = pickle.load(f)\n",
    "    print(\"✓ Loaded cached combined test data.\")\n",
    "else:\n",
    "    test_eff, test_zern, test_labels, _ = build_sequences_combined(test_path)\n",
    "    with open(test_cache, 'wb') as f:\n",
    "        pickle.dump((test_eff, test_zern, test_labels), f)\n",
    "    print(\"✓ Combined test data preprocessed and cached.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137f61a",
   "metadata": {},
   "source": [
    "### Preprocess Feature Sequences\n",
    "Pads both EfficientNet and Zernike sequences to the maximum sequence length and converts labels to one-hot encoding for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('train_data_dual_stream_letters_10_zern8.pkl', 'rb') as f:\n",
    "    train_eff, train_zern, train_labels, label_map = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('test_data_dual_stream_letters_10_zern8.pkl', 'rb') as f:\n",
    "    test_eff, test_zern, test_labels = pickle.load(f)\n",
    "\n",
    "\n",
    "max_seq_len = 10  \n",
    "\n",
    "def pad(data): return pad_sequences(data, maxlen=max_seq_len, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "X_train_eff = pad(train_eff)\n",
    "X_test_eff  = pad(test_eff)\n",
    "\n",
    "# Option 1: Keep Zernike features as 3D (T, 12, ZERN_FEATURE_SIZE)\n",
    "X_train_zern = pad(train_zern)\n",
    "X_test_zern  = pad(test_zern)\n",
    "\n",
    "# === One-hot encode labels ===\n",
    "num_classes = len(label_map)\n",
    "y_train = to_categorical(train_labels, num_classes=num_classes)\n",
    "y_test  = to_categorical(test_labels, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f703764",
   "metadata": {},
   "source": [
    "### Define Custom F1 Score Metric\n",
    "Implements a custom Keras metric to calculate F1 Score during training using internal precision and recall metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16729944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, TopKCategoricalAccuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd943a",
   "metadata": {},
   "source": [
    "### Build Dual-Stream Model\n",
    "Defines a dual-stream model: one for EfficientNet features processed with Multi-Head Attention, and another for Zernike features processed with LSTM. The two are fused via attention and residual connection before final classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, Bidirectional, LSTM, LayerNormalization,\n",
    "    MultiHeadAttention, GlobalAveragePooling1D, Concatenate, TimeDistributed, Flatten, Add\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "EFF_DIM = 2 * FEATURE_SIZE           \n",
    "ZERN_SEQ_DIM = 12                    \n",
    "ZERN_FEAT_DIM = ZERN_FEATURE_SIZE   \n",
    "SEQ_LEN = 10                       \n",
    "NUM_CLASSES = len(label_map)         \n",
    "FUSION_DIM = 64                     \n",
    "\n",
    "\n",
    "eff_input = Input(shape=(SEQ_LEN, EFF_DIM), name='eff_input')\n",
    "x_eff = Dense(FUSION_DIM)(eff_input)  \n",
    "x_eff = LayerNormalization()(x_eff)\n",
    "x_eff = MultiHeadAttention(num_heads=4, key_dim=FUSION_DIM)(x_eff, x_eff)\n",
    "x_eff = Dropout(0.3)(x_eff)\n",
    "x_eff = Dense(FUSION_DIM, activation='relu')(x_eff)\n",
    "\n",
    "zern_input = Input(shape=(SEQ_LEN, ZERN_SEQ_DIM, ZERN_FEAT_DIM), name='zern_input')\n",
    "zern_flat = TimeDistributed(Flatten())(zern_input)  \n",
    "zern_proj = Dense(FUSION_DIM)(zern_flat) \n",
    "zern_lstm = Bidirectional(LSTM(FUSION_DIM, return_sequences=True))(zern_proj)\n",
    "zern_lstm = Dropout(0.3)(zern_lstm)\n",
    "\n",
    "\n",
    "attended = MultiHeadAttention(num_heads=4, key_dim=FUSION_DIM)(\n",
    "    query=x_eff,\n",
    "    key=zern_lstm,\n",
    "    value=zern_lstm\n",
    ")\n",
    "\n",
    "\n",
    "fused = Add()([x_eff, attended])\n",
    "fused = LayerNormalization()(fused)\n",
    "\n",
    "\n",
    "fused_pooled = GlobalAveragePooling1D()(fused)\n",
    "x = Dropout(0.4)(fused_pooled)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[eff_input, zern_input], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        Precision(name='precision'),\n",
    "        F1Score(name='f1_score')  \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82eee3",
   "metadata": {},
   "source": [
    "### Compile and Train Model\n",
    "Compiles the model using categorical crossentropy, accuracy, precision, and F1 metrics, and trains using early stopping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x={'eff_input': X_train_eff, 'zern_input': X_train_zern},\n",
    "    y=y_train,\n",
    "    validation_data=(\n",
    "        {'eff_input': X_test_eff, 'zern_input': X_test_zern},\n",
    "        y_test\n",
    "    ),\n",
    "    epochs=200,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e796f",
   "metadata": {},
   "source": [
    "### Visualize Training Metrics\n",
    "Plots loss, accuracy, precision, and F1 score over training epochs for both training and validation datasets using Matplotlib and Seaborn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# === Configure Seaborn Theme ===\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# === Function to Plot Metrics ===\n",
    "def plot_metric(history, metric, title=None, ylabel=None):\n",
    "    train = history.history.get(metric)\n",
    "    val = history.history.get(f'val_{metric}')\n",
    "    \n",
    "    if train is None or val is None:\n",
    "        return  # Skip if metric not found\n",
    "\n",
    "    epochs = range(1, len(train) + 1)\n",
    "    \n",
    "    # Custom colors like the reference image\n",
    "    train_color = '#1f77b4'  # Blue\n",
    "    val_color = '#ff5733'    # Red/Orange\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train, label=\"Train\", color=train_color, linewidth=2)\n",
    "    plt.plot(epochs, val, label=\"Test\", color=val_color, linewidth=2)\n",
    "\n",
    "\n",
    "    # Labels and title\n",
    "    plt.title(title or f\"{metric.capitalize()} Over Epochs\", fontsize=16)\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(ylabel or metric.capitalize(), fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Plotting ===\n",
    "plot_metric(history, 'loss', title=\"Training vs Validation Loss\", ylabel=\"Loss\")\n",
    "plot_metric(history, 'accuracy', title=\"Training vs Validation Accuracy\", ylabel=\"Accuracy\")\n",
    "\n",
    "# Optional: Add these only if these metrics exist in your model\n",
    "for metric in ['precision', 'f1_score']:\n",
    "    plot_metric(history, metric, title=f\"Training vs Validation {metric.capitalize()}\", ylabel=metric.capitalize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model\n",
    "model.save('model_dual_stream_letters.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
